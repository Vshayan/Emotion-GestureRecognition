# Emotion and Hand Gesture Recognition

This project integrates face emotion recognition and hand gesture tracking to create a robust system that can detect and interpret human emotions and hand gestures in real time. Using a combination of computer vision techniques and machine learning models, the system can identify various emotions displayed on a person's face and track specific hand gestures.

# Key Features:
* Face Emotion Recognition: Utilizes the FER (Facial Emotion Recognition) library to detect and classify emotions such as happiness, sadness, anger, and more from facial expressions.
* Hand Gesture Tracking: Employs MediaPipe's Hand solution to detect and track hand landmarks, allowing for the identification of gestures like thumbs up, victory, OK sign, and others.
* Real-Time Processing: Capable of processing video input from a webcam in real time, providing immediate feedback on detected emotions and gestures.
* Interactive Visuals: The system overlays information and labels directly on the video feed, making it easy to see the detected emotions and gestures.

# Dependencies:

The following libraries and versions are used in this project:

``` python
Python: 3.12.3
FER: 22.5.1
mediapipe: 0.10.14
numpy: 1.26.4
opencv: 4.9.0
```
